# -*- coding: utf-8 -*-
"""
main.py
é€šç”¨ä¸»ç¨‹åº - æ”¯æŒå•æ•°æ®é›†å’Œè·¨æ•°æ®é›†è‡ªåŠ¨é¡ºåºæ‰§è¡Œ
"""

import numpy as np
import pandas as pd
from datetime import datetime
import argparse

from config import get_config, STANDARD_BANDS
from data_loader import load_dataset
from feature_extraction import (
    extract_traditional_features,
    extract_1f_features_single_band_enhanced,
    build_pca_cross_features,
    build_stacking_features
)
from evaluation import EnhancedModelEvaluator  # âœ… æ­£ç¡®çš„å¯¼å…¥


def run_single_dataset_experiment(dataset_name='SAD'):
    """
    å•æ•°æ®é›†å®éªŒæµç¨‹

    Parameters:
    -----------
    dataset_name : str
        æ•°æ®é›†åç§° ('SAD', 'SEED', æˆ–è‡ªå®šä¹‰)

    Returns:
    --------
    dict: åŒ…å«ç‰¹å¾å’Œæ ‡ç­¾çš„å­—å…¸ï¼Œç”¨äºåç»­è·¨æ•°æ®é›†éªŒè¯
    """
    print(f"\n{'#' * 60}")
    print(f"# å•æ•°æ®é›†å®éªŒ: {dataset_name}")
    print(f"{'#' * 60}\n")

    # ==================== 1. åŠ è½½é…ç½®å’Œæ•°æ® ====================
    config = get_config(dataset_name)
    config.get_info()

    data_dict = load_dataset(config)
    EEGsample = data_dict['X']
    labels = data_dict['y']

    print(f"\næ•°æ®åŠ è½½å®Œæˆ: {len(labels)} samples, {config.n_classes} classes")

    # ==================== 2. åˆå§‹åŒ–è¯„ä¼°å™¨ ====================
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = config.output_dir / f"single_dataset_{dataset_name}_{ts}"

    evaluator = EnhancedModelEvaluator(
        n_splits=5,
        random_state=42,
        save_dir=str(save_dir)
    )
    print(f"âœ… è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {save_dir}")

    # ==================== 3. æå–ä¼ ç»Ÿç‰¹å¾ ====================
    print("\nğŸš€ æå–ä¼ ç»Ÿ EEG ç‰¹å¾...")
    X_trad, feature_info_trad = extract_traditional_features(EEGsample, config)
    print(f"âœ… ä¼ ç»Ÿç‰¹å¾å®Œæˆï¼Œå½¢çŠ¶ï¼š{X_trad.shape}")

    # ==================== 4. æå–1/fç‰¹å¾ï¼ˆä¸»é¢‘æ®µï¼‰====================
    print("\nğŸš€ æå–1/fç‰¹å¾ (1-40Hz)...")
    X_1f_main, feature_info_1f = extract_1f_features_single_band_enhanced(
        EEGsample, config, fmin=1, fmax=40
    )
    print(f"âœ… 1/fç‰¹å¾å®Œæˆï¼Œå½¢çŠ¶ï¼š{X_1f_main.shape}")

    # ==================== 5. åŸºçº¿è¯„ä¼° ====================
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š åŸºçº¿è¯„ä¼°ï¼šä¼ ç»ŸEEGç‰¹å¾")
    print(f"{'=' * 60}")

    class_names = config.class_names

    baseline_results = evaluator.evaluate_single_dataset(
        X_trad, labels,
        class_names=class_names,
        method_name='Baseline_Traditional'
    )

    # ==================== 6. å¤šé¢‘æ®µå®éªŒ ====================
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š å¤šé¢‘æ®µ1/fç‰¹å¾è¯„ä¼°")
    print(f"{'=' * 60}")

    roc_methods_configs = [
        {'name': 'Baseline (Traditional)', 'X': X_trad}
    ]

    for label, fmin, fmax in STANDARD_BANDS:
        print(f"\n{'=' * 60}")
        print(f"--- é¢‘æ®µ: {label} ({fmin}-{fmax} Hz) ---")
        print(f"{'=' * 60}")

        X_1f_band, _ = extract_1f_features_single_band_enhanced(
            EEGsample, config, fmin=fmin, fmax=fmax
        )

        method_name_1f = f"1f_only_{label}"
        evaluator.evaluate_single_dataset(
            X_1f_band, labels,
            class_names=class_names,
            method_name=method_name_1f
        )

        X_fused = np.hstack([X_1f_band, X_trad])
        method_name_fused = f"Fused_{label}"
        evaluator.evaluate_single_dataset(
            X_fused, labels,
            class_names=class_names,
            method_name=method_name_fused
        )

        roc_methods_configs.append({
            'name': f'{label} (Fused)',
            'X': X_fused
        })

    # ==================== 7. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ====================
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ")
    print(f"{'=' * 60}")

    comparison_methods = [k for k in evaluator.results.keys()
                          if k != 'Baseline_Traditional']

    if len(comparison_methods) > 0:
        significance_results = evaluator.statistical_significance_test(
            baseline_method='Baseline_Traditional',
            comparison_methods=comparison_methods
        )

    # ==================== 8. ROCæ›²çº¿å¯¹æ¯” ====================
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ROCæ›²çº¿å¯¹æ¯”ï¼ˆæ‰€æœ‰æ–¹æ³•ï¼‰")
    print(f"{'=' * 60}")

    evaluator.plot_roc_curves_comparison(
        X_trad, labels,
        roc_methods_configs,
        class_names=class_names
    )

    # ==================== 9. ç‰¹å¾é‡è¦æ€§åˆ†æ ====================
    if X_1f_main.shape[1] <= 500:
        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆ1/fä¸»é¢‘æ®µï¼‰")
        print(f"{'=' * 60}")

        feature_names_1f = feature_info_1f['names']

        evaluator.feature_importance_analysis(
            X_1f_main, labels,
            feature_names=feature_names_1f,
            method_name='1f_main_band',
            top_k=min(20, len(feature_names_1f))
        )

    # ==================== 10. è¢«è¯•çº§åˆ†æ ====================
    if 'subject' in data_dict:
        print(f"\n{'=' * 60}")
        print(f"ğŸ“Š è¢«è¯•çº§åˆ†æï¼ˆLeave-One-Subject-Outï¼‰")
        print(f"{'=' * 60}")

        subject_indices = data_dict['subject']

        subject_results = evaluator.leave_one_subject_out_analysis(
            X_1f_main, labels, subject_indices,
            class_names=class_names,
            method_name='1f_main_LOSO'
        )

        print(f"âœ… è¢«è¯•çº§åˆ†æå®Œæˆ")

    # ==================== 11. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š ====================
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
    print(f"{'=' * 60}")

    summary_df = evaluator.generate_summary_report()

    # ==================== 12. ä¿å­˜ä¼ ç»Ÿæ ¼å¼ç»“æœ ====================
    results_rows = []

    for method_name, results in evaluator.results.items():
        if 'mean_metrics' in results:
            metrics = results['mean_metrics']

            if method_name == 'Baseline_Traditional':
                band = 'Baseline'
                group = 'ä¼ ç»ŸEEGç‰¹å¾'
            elif method_name.startswith('1f_only_'):
                band = method_name.replace('1f_only_', '')
                group = 'ä»…1/f'
            elif method_name.startswith('Fused_'):
                band = method_name.replace('Fused_', '')
                group = 'èåˆ'
            else:
                band = 'Other'
                group = method_name

            results_rows.append({
                "Dataset": dataset_name,
                "Band": band,
                "Group": group,
                "AUC_mean": f"{metrics['auc']:.4f}",
                "Acc_mean": f"{metrics['accuracy']:.4f}",
                "Precision": f"{metrics['precision']:.4f}",
                "Recall": f"{metrics['recall']:.4f}",
                "F1-Score": f"{metrics['f1']:.4f}"
            })

    df_legacy = pd.DataFrame(results_rows)
    legacy_file = save_dir / f"legacy_results_{dataset_name}.csv"
    df_legacy.to_csv(legacy_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ä¼ ç»Ÿæ ¼å¼ç»“æœå·²ä¿å­˜: {legacy_file}")

    print(f"\n{'=' * 60}")
    print(f"âœ… {dataset_name} å•æ•°æ®é›†è¯„ä¼°å®Œæˆï¼")
    print(f"{'=' * 60}")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {save_dir}")

    # è¿”å›æ•°æ®ä¾›è·¨æ•°æ®é›†ä½¿ç”¨
    return {
        'dataset_name': dataset_name,
        'config': config,
        'EEGsample': EEGsample,
        'labels': labels,
        'X_trad': X_trad,
        'X_1f_main': X_1f_main,
        'class_names': class_names
    }


def run_cross_dataset_experiment(train_data, test_data):
    """
    è·¨æ•°æ®é›†éªŒè¯å®éªŒ

    Parameters:
    -----------
    train_data : dict
        è®­ç»ƒæ•°æ®é›†ä¿¡æ¯ï¼ˆæ¥è‡ªrun_single_dataset_experimentï¼‰
    test_data : dict
        æµ‹è¯•æ•°æ®é›†ä¿¡æ¯ï¼ˆæ¥è‡ªrun_single_dataset_experimentï¼‰
    """
    train_dataset = train_data['dataset_name']
    test_dataset = test_data['dataset_name']

    print(f"\n{'#' * 60}")
    print(f"# è·¨æ•°æ®é›†éªŒè¯: {train_dataset} â†’ {test_dataset}")
    print(f"{'#' * 60}\n")

    config_train = train_data['config']
    config_test = test_data['config']

    # ç¡®ä¿ç±»åˆ«æ•°ä¸€è‡´
    if config_train.n_classes != config_test.n_classes:
        print(f"âš ï¸ è­¦å‘Š: ç±»åˆ«æ•°ä¸ä¸€è‡´ ({config_train.n_classes} vs {config_test.n_classes})")
        print("è·¨æ•°æ®é›†éªŒè¯éœ€è¦ç›¸åŒçš„ç±»åˆ«æ•°ï¼Œè·³è¿‡æ­¤éªŒè¯")
        return

    # åˆå§‹åŒ–è¯„ä¼°å™¨
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = config_train.output_dir / f"cross_dataset_{train_dataset}_to_{test_dataset}_{ts}"

    evaluator = EnhancedModelEvaluator(
        n_splits=5,
        random_state=42,
        save_dir=str(save_dir)
    )

    # æå–è®­ç»ƒé›†ç‰¹å¾
    print("\nğŸš€ æå–è®­ç»ƒé›†ç‰¹å¾...")
    X_train_trad, _ = extract_traditional_features(
        train_data['EEGsample'], config_train
    )
    X_train_1f, _ = extract_1f_features_single_band_enhanced(
        train_data['EEGsample'], config_train, fmin=1, fmax=40
    )
    X_train_fused = np.hstack([X_train_1f, X_train_trad])

    # æå–æµ‹è¯•é›†ç‰¹å¾
    print("ğŸš€ æå–æµ‹è¯•é›†ç‰¹å¾...")
    X_test_trad, _ = extract_traditional_features(
        test_data['EEGsample'], config_test
    )
    X_test_1f, _ = extract_1f_features_single_band_enhanced(
        test_data['EEGsample'], config_test, fmin=1, fmax=40
    )
    X_test_fused = np.hstack([X_test_1f, X_test_trad])

    y_train = train_data['labels']
    y_test = test_data['labels']
    class_names = train_data['class_names']

    # è·¨æ•°æ®é›†éªŒè¯
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š è·¨æ•°æ®é›†éªŒè¯")
    print(f"{'=' * 60}")

    # ä¼ ç»Ÿç‰¹å¾
    print("\n--- ä¼ ç»Ÿç‰¹å¾ ---")
    evaluator.cross_dataset_validation(
        X_train_trad, y_train, X_test_trad, y_test,
        class_names, train_name=train_dataset,
        test_name=test_dataset + '_Traditional'
    )

    # 1/fç‰¹å¾
    print("\n--- 1/fç‰¹å¾ ---")
    evaluator.cross_dataset_validation(
        X_train_1f, y_train, X_test_1f, y_test,
        class_names, train_name=train_dataset,
        test_name=test_dataset + '_1f'
    )

    # èåˆç‰¹å¾
    print("\n--- èåˆç‰¹å¾ ---")
    evaluator.cross_dataset_validation(
        X_train_fused, y_train, X_test_fused, y_test,
        class_names, train_name=train_dataset,
        test_name=test_dataset + '_Fused'
    )

    print(f"\n{'=' * 60}")
    print(f"âœ… {train_dataset} â†’ {test_dataset} è·¨æ•°æ®é›†éªŒè¯å®Œæˆï¼")
    print(f"{'=' * 60}")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {save_dir}")


def run_complete_pipeline(datasets=['SAD', 'SEED']):
    """
    å®Œæ•´å®éªŒæµç¨‹ï¼šå…ˆå•æ•°æ®é›†ï¼Œå†è·¨æ•°æ®é›†

    Parameters:
    -----------
    datasets : list
        è¦è¿è¡Œçš„æ•°æ®é›†åˆ—è¡¨
    """
    print(f"\n{'#' * 80}")
    print(f"# å¼€å§‹å®Œæ•´å®éªŒæµç¨‹")
    print(f"# æ•°æ®é›†: {', '.join(datasets)}")
    print(f"{'#' * 80}\n")

    # ==================== é˜¶æ®µ1: å•æ•°æ®é›†å®éªŒ ====================
    print(f"\n{'=' * 80}")
    print(f"é˜¶æ®µ 1/2: å•æ•°æ®é›†è¯„ä¼°")
    print(f"{'=' * 80}\n")

    dataset_results = {}

    for dataset_name in datasets:
        data_info = run_single_dataset_experiment(dataset_name)
        dataset_results[dataset_name] = data_info

    # ==================== é˜¶æ®µ2: è·¨æ•°æ®é›†éªŒè¯ ====================
    if len(datasets) >= 2:
        print(f"\n{'=' * 80}")
        print(f"é˜¶æ®µ 2/2: è·¨æ•°æ®é›†éªŒè¯")
        print(f"{'=' * 80}\n")

        # è¿›è¡Œæ‰€æœ‰å¯èƒ½çš„è·¨æ•°æ®é›†éªŒè¯
        for i, train_dataset in enumerate(datasets):
            for j, test_dataset in enumerate(datasets):
                if i != j:  # ä¸åŒæ•°æ®é›†ä¹‹é—´
                    run_cross_dataset_experiment(
                        dataset_results[train_dataset],
                        dataset_results[test_dataset]
                    )
    else:
        print(f"\nâš ï¸ åªæœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œè·³è¿‡è·¨æ•°æ®é›†éªŒè¯")

    # ==================== æ€»ç»“ ====================
    print(f"\n{'#' * 80}")
    print(f"âœ… å®Œæ•´å®éªŒæµç¨‹å®Œæˆï¼")
    print(f"{'#' * 80}")
    print(f"\nå·²å®Œæˆçš„å®éªŒ:")
    print(f"  - å•æ•°æ®é›†è¯„ä¼°: {len(datasets)} ä¸ªæ•°æ®é›†")
    if len(datasets) >= 2:
        n_cross = len(datasets) * (len(datasets) - 1)
        print(f"  - è·¨æ•°æ®é›†éªŒè¯: {n_cross} ä¸ªç»„åˆ")
    print(f"\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°å„è‡ªçš„ç›®å½•ä¸­")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='é€šç”¨EEGç–²åŠ³æ£€æµ‹å®éªŒï¼ˆå¢å¼ºç‰ˆï¼‰')
    parser.add_argument('--dataset', type=str, default='SAD',
                        choices=['SAD', 'SEED', 'all'],
                        help='æ•°æ®é›†åç§°ï¼ˆall=è¿è¡Œå…¨éƒ¨å¹¶è‡ªåŠ¨è·¨æ•°æ®é›†éªŒè¯ï¼‰')
    parser.add_argument('--mode', type=str, default='auto',
                        choices=['single', 'cross', 'auto'],
                        help='å®éªŒæ¨¡å¼: single=ä»…å•æ•°æ®é›†, cross=ä»…è·¨æ•°æ®é›†, auto=è‡ªåŠ¨å®Œæ•´æµç¨‹ï¼ˆé»˜è®¤ï¼‰')
    parser.add_argument('--train_dataset', type=str, default='SAD',
                        help='è·¨æ•°æ®é›†å®éªŒçš„è®­ç»ƒé›†ï¼ˆä»…åœ¨mode=crossæ—¶ä½¿ç”¨ï¼‰')
    parser.add_argument('--test_dataset', type=str, default='SEED',
                        help='è·¨æ•°æ®é›†å®éªŒçš„æµ‹è¯•é›†ï¼ˆä»…åœ¨mode=crossæ—¶ä½¿ç”¨ï¼‰')

    args = parser.parse_args()

    if args.mode == 'auto':
        # âœ… è‡ªåŠ¨å®Œæ•´æµç¨‹ï¼ˆæ¨èï¼‰
        if args.dataset == 'all':
            run_complete_pipeline(['SAD', 'SEED'])
        else:
            run_complete_pipeline([args.dataset])

    elif args.mode == 'single':
        # ä»…å•æ•°æ®é›†å®éªŒ
        if args.dataset == 'all':
            for dataset_name in ['SAD', 'SEED']:
                run_single_dataset_experiment(dataset_name)
        else:
            run_single_dataset_experiment(args.dataset)

    elif args.mode == 'cross':
        # ä»…è·¨æ•°æ®é›†éªŒè¯
        train_data = run_single_dataset_experiment(args.train_dataset)
        test_data = run_single_dataset_experiment(args.test_dataset)
        run_cross_dataset_experiment(train_data, test_data)
